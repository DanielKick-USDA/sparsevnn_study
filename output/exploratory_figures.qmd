---
title: "Untitled"
format: html
editor: source
---

<!-- x = system('ls', intern = TRUE) -->


Before working with the data in output ensure it's up to date. This can be done by running
`cd /home/daniel.kick/daniel/sparsevnn_study/output && sbatch refresh_data.sbatch`


```{r}
rm(list = ls()) # yeah, yeah, I know. 
setwd("~/daniel/sparsevnn_study/output")


library(arrow)
library(tidyverse)

# run on hpc
# install.packages('viridis')
# install.packages('patchwork')
# install.packages('ggh4x')

# install.packages('ggthemes')
# library(ggthemes) # for tufte
# if using scales take a look at
  # scale_y_log10(labels = label_log())+
  # scale_y_log10()+
  # label_log(base = 10, digits = 3)+
  # scale_y_continuous(labels = scales::comma)+


library(ggtext) # for element markdown

library(viridis)
library(patchwork)
library(cowplot)
library('ggh4x')
options(scipen = 10L)
```

# Custom
```{r}
# Return metrics as a tidy df
load_model_metrics <- function(
    path = '../data_gmx_lsuv_tanh/phno_OilDry/vnn/models/vnn/version_0/metrics.csv',
    tidy = T
){
  metrics <- read_csv(path)
  if(tidy == TRUE){
    metrics <- rbind(
      
      (metrics |>
         select(-val_loss) |>
         drop_na() |>
         mutate(split = 'trn', loss = train_loss )|>
         select(-train_loss)),
      
      (metrics |>
         select(-train_loss) |>
         drop_na() |>
         mutate(split = 'val', loss = val_loss )|>
         select(-val_loss))
    )
  }
  return(
    list(
      metrics=metrics
    ))      
}
```

```{r}
# moved from Hyps Performance
plt_net_metrics <- function(md, phno_i, phase_i, show_min_loss = FALSE){
  tmp_md <- md |> 
    filter(
      phase == phase_i, 
      info == 'metrics', 
      phno == phno_i
    ) 
  
  tmp_md <- tmp_md |>
    mutate(init = case_when(
      str_detect(data, 'lsuv_relu$') ~ 'l.relu',
      str_detect(data, 'lsuv_tanh$') ~ 'l.tanh',
      str_detect(data, 'lsuv_vlin$') ~ 'l.none',
      TRUE ~ 'r.tanh'
    )) 
  
  tmp_dl <- map(tmp_md$path, function(ii){mutate(load_model_metrics(ii)$metrics, path=ii)})
  
  tmp_dl <- full_join(tmp_md, do.call(rbind, tmp_dl) )
  
  # NOTE without modificaiton to the init field it's best to filter the records
  # tmp_dl <- tmp_dl |> filter(model == 'vnn')
  tmp_dl <- tmp_dl |> 
    mutate(init = paste0(model, '.', init)) 
  
  
  tmp_dl <- full_join(
    tmp_dl, 
    expand.grid(
      phno = phno_i,
      split = c('trn', 'val'),
      init = c(
        'dnn.r.tanh', 
        'vnn.r.tanh', 
        'vnn.l.tanh', 
        'vnn.l.relu',
        'vnn.l.none'
    )
    )) |>  
    mutate(init = factor(init, levels = c(
      'dnn.r.tanh', 
      'vnn.r.tanh', 
      'vnn.l.tanh', 
      'vnn.l.relu',
      'vnn.l.none'
    )))
  
  
  tmp_dl_envelope <- tmp_dl |>
    filter(split == 'trn') |>
    # filter(model == 'vnn', split == 'trn') |>
    group_by(data, phno, model, init, split, epoch) |>
    mutate(
      min_trn = case_when(split == 'trn' ~ min(loss)),
      max_trn = case_when(split == 'trn' ~ max(loss)) )   |>
    select(-loss, -step) |>
    distinct()
  
  
  if (phase_i == 'lightning'){
    # color by percent of trials
    # plt <- tmp_dl |>
    #   filter(split == 'val') |>
    #   mutate(v = as.numeric(str_extract(version, '\\d+$'))) |>
    #   group_by(data, phno, model, phase, init) |>
    #   mutate(pr.trial = v/max(v)) |>
    #   ggplot(aes(x = epoch, group = path))+
    #   geom_ribbon(data=tmp_dl_envelope, aes(ymin=min_trn, ymax=max_trn), alpha = 0.3)+
    #   geom_line(aes(y = loss, color =  pr.trial))+
    #   theme_minimal()+
    #   facet_grid(phno~init)
    
    # Show last entry
    tmp_dl_plt <-  tmp_dl |>
      filter(split == 'val') |>
      mutate(v = as.numeric(str_extract(version, '\\d+$'))) |>
      group_by(data, phno, model, phase, init) |>
      mutate(last.trial = case_when(v == max(v) ~ TRUE, 
                                    TRUE ~ FALSE)) |>
      arrange(epoch, step)
    
    plt <- tmp_dl_plt |>
      ggplot(aes(x = epoch, group = path))+
      geom_ribbon(data=tmp_dl_envelope, aes(ymin=min_trn, ymax=max_trn), alpha = 0.1)+
      geom_line(aes(y = loss), color = 'lightgrey', alpha = 0.6)+
      geom_line(data = filter(tmp_dl_plt, last.trial == TRUE), aes(y = loss), color = 'red')+
      theme_minimal()+
      facet_grid(phno~init)+
      # scale_color_manual(values = c('lightgrey', 'firebrick'))+
      theme(legend.position = 'none')

  } else if (phase_i == 'models'){
    
    plt <- tmp_dl |>
      filter(split == 'val') |>
      arrange(epoch, step) |>
      # filter(model == 'vnn', split == 'val') |>
      ggplot(aes(x = epoch, group = path))+
      geom_ribbon(data=tmp_dl_envelope, aes(ymin=min_trn, ymax=max_trn), alpha = 0.3)+
      geom_line(aes(y = loss))+
      theme_minimal()+
      # coord_cartesian(xlim = c(0, 1))+
      facet_grid(phno~init)
  }
  
  if(show_min_loss == TRUE){
    # find the lowest validation observation and adorn all the plots
  
    tmp_dl_hline <- tmp_dl |>
      filter(split == 'val') |>
      arrange(epoch, step)
    
    tmp_dl_hline <- left_join(
      (tmp_dl_hline |>
         group_by(data, phno, model, phase, init) |>
         summarize(loss = min(loss, na.rm = T)) |>
         ungroup()),
      tmp_dl_hline
    ) |> 
      ungroup() |>
      mutate(min_loss = min(loss, na.rm = T))
    
    
    # plt <- tmp_dl |>
    #     filter(split == 'val') |>
    #     arrange(epoch, step) |>
    #     # filter(model == 'vnn', split == 'val') |>
    #     ggplot(aes(x = epoch, group = path))+
    #     geom_ribbon(data=tmp_dl_envelope, aes(ymin=min_trn, ymax=max_trn), alpha = 0.3)+
    #     geom_line(aes(y = loss))+
    #     theme_minimal()+
    #     # coord_cartesian(xlim = c(0, 1))+
    #     facet_grid(phno~init)+
    #     scale_y_continuous(
    #         trans = "log10",
    #         breaks = c(0.5, 1, 10, 100, 1000)
    #     )
    
    plt <- plt+geom_hline(
      data = tmp_dl_hline, 
      aes(yintercept = min_loss), 
      color = 'cornflowerblue', 
      linetype = 'solid'
    )+
      geom_segment(
        data = tmp_dl_hline, 
        aes(x = epoch, y = loss, xend = epoch, yend = min_loss),
        arrow = arrow(length = unit(5, "pt"), type = "closed"),
        color = "orange",
        # size = 1.5,
        linetype = 'solid'
      )
  }
  
  return(plt)
}

```



# All Metadata

```{r}
md <- list()

md$net_hist <- data.frame(path = system("find ../data_* -name metrics.csv",             intern = T))
md$net_pred <- data.frame(path = system("find ../data_* -name '*_y[hv]a[tr]_*parquet'", intern = T))
md$net_eval <- data.frame(path = system("find ../data_* -name '*_eval_*parquet'",       intern = T))
md$lin_blup <- data.frame(path = system("find ../data_* -name '*_bWGR_yhat.parquet'",   intern = T))

# have to ignore everything that isn't lin/models
x <- system("find ../data_* -name 'GAPIT.Association.GWAS_Results.BLINK.*.csv'", intern = T)
x <- x[str_detect(x, 'lin/models/gwas')]
md$lin_gwas <- data.frame(path = x)



# cleaning metadata
md_net_pth <- function(M){
  M <- M |> 
  separate_wider_delim(
    path, 
    "/", 
    names = c("drp1", "data", "phno", "model", "phase", "drp2", "version", "file"), 
    too_many = "drop", 
    cols_remove = F
    ) |> 
  select(-drp1, -drp2)
  
  return(M)
}


md$net_hist <- md_net_pth(M = md$net_hist) |> 
  separate_wider_delim(file, ".",
                       names = c("info"), 
                       too_many = "drop",
                       cols_remove = T)

md$net_pred <- md_net_pth(M = md$net_pred) |> 
  separate_wider_delim(file, ".",
                       names = c("info"), 
                       too_many = "drop",
                       cols_remove = T) |> 
  separate_wider_delim(info, "_",
                       names = c("hash", "info"), 
                       too_many = "merge",
                       cols_remove = T) 

md$net_eval <- md_net_pth(M = md$net_eval) |> 
  separate_wider_delim(file, "_",
                       names = c("hash", "info"), 
                       too_many = "merge",
                       cols_remove = T) |> #select(-hash) |>
  separate_wider_delim(info, ".",
                       names = c("info", "rm"), 
                       too_many = "merge",
                       cols_remove = T) |> select(-rm) |>
  distinct()



md$lin_blup <- md$lin_blup |>
  separate_wider_delim(path,"/",
                       names = c("drp1", "data", "phno", "model", "phase", "drp2", "file"), 
                       too_many = "drop", 
                       cols_remove = F) |> select(-drp1, -drp2) |>
  separate_wider_delim(file, "_",
                       names = c("hash", "info"), 
                       too_many = "merge",
                       cols_remove = T) |>
  separate_wider_delim(info, ".",
                       names = c("info"), 
                       too_many = "drop",
                       cols_remove = T) 


md$lin_gwas <- md$lin_gwas |>
  separate_wider_delim(path,"/",
                       names = c("drp1", "data", "phno", "model", "phase", "drp2", "file"), 
                       too_many = "drop", 
                       cols_remove = F) |> select(-drp1, -drp2) |>
  rename(info = file)


md <- full_join(md$net_hist, md$net_pred) |> 
  full_join(md$net_eval) |>
  full_join(md$lin_blup) |>
  full_join(md$lin_gwas)


# Drop phenotypes that we're ignoring going forward
md <- md |> 
  filter(!(phno %in% c("phno_all_Pollen_GDD__WIH2_2020", 
                       "phno_all_Yield_Mg_ha__IAH3_2021")))

phno_iter <- sort(unique(md$phno))

md
```



## [X] Hyps Stabilization

```{r hyps vis 1a, eval=FALSE}
# Hyperparameters ---


plt_hyps_grid_vnn <- function(
    M, 
    hyps_cols = c(
  "train_loss", 
  "default_out_nodes_inp", "default_out_nodes_edge", 
  "default_drop_nodes_inp", "default_drop_nodes_edge", "default_drop_nodes_out", 
  "default_reps_nodes_inp", "default_reps_nodes_edge", "default_reps_nodes_out", 
  "default_decay_rate"#, "default_out_nodes_out"
  )
    ){
  plt <- M |>
    pivot_longer(cols = all_of(hyps_cols)) |>
    group_by(exp, phn, model, name) |>
    # set scaling col
    mutate(pr_max = (value - min(value))/(max(value) - min(value)) ) |>
    ungroup() |>
    # do fussy things with the name column so that the hyperparameters can be grouped
    mutate(
      node_type = case_when(
        str_detect(name, 'nodes_inp') ~ 'Input',
        str_detect(name, 'nodes_edge') ~ 'Edge',
        str_detect(name, 'nodes_out') ~ 'Output',
        
        str_detect(name, 'train_loss') ~ 'Loss',
        TRUE ~ 'All'
      ),
      node_attr = case_when(
        str_detect(name, 'reps')  ~ 'Repeats',
        str_detect(name, '_out_') ~ 'Output',
        str_detect(name, 'drop')  ~ 'Dropout',
        str_detect(name, 'decay') ~ 'Decay',
        
        str_detect(name, 'train_loss') ~ ''
      )
    )|> 
    mutate(
      node_type = factor(node_type, levels = c('Output', 'Edge', 'Input', 'All', 'Loss')),
      node_attr = factor(node_attr, levels = c('Decay', 'Dropout', 'Repeats', 'Output', ''))
    ) |>
    
    ggplot(aes(x = trial_index, y = interaction(node_type, node_attr), fill = 100*pr_max))+
    geom_tile()+
    scale_y_discrete(guide = "axis_nested")+
    labs(x = 'Hyperparameter Set', y = '', title = 'Iterative Improvement of Hyperparameters', fill = '% Max')+
    theme(panel.background = element_rect(fill = "white", colour = NA),
          axis.ticks = element_line(colour = 'gray'))
  
  return(plt)
  
}


plt_hyps_grid_dnn <- function(
    M, 
    hyps_cols = c(
  "train_loss", 
  "hidden_layers", "width", "drop", 
  "width_decay_rate", "drop_decay_rate", 
  "width_decay_reverse", "drop_decay_reverse"#, 
  # "size_out",
  # "size_in"
  )
    ){
  plt <- M |>
    pivot_longer(cols = all_of(hyps_cols)) |>
    filter(!(name %in% c("size_out", "size_in"))) |>
    group_by(exp, phn, model, name) |>
    # set scaling col
    mutate(pr_max = (value - min(value))/(max(value) - min(value)) ) |>
    ungroup() |>
    # do fussy things with the name column so that the hyperparameters can be grouped
    mutate(
      node_type = case_when(
        str_detect(name, 'hidden_layers') ~ 'Depth',
        str_detect(name, 'width') ~ 'Width',
        str_detect(name, 'drop') ~ 'Dropout',
        str_detect(name, '_rate') ~ 'Rate',
        str_detect(name, '_reverse') ~ 'Direction',
        str_detect(name, 'train_loss') ~ 'Loss'
        # TRUE ~ 'All'
      ),
      node_attr = case_when(
        str_detect(name, 'decay') ~ 'Decay',
        str_detect(name, 'train_loss') ~ '',
        TRUE ~ 'Base'
      )
    ) |> 
    mutate(
      node_type = factor(node_type, levels = c('Depth', 'Width', 'Dropout', 'Rate', 'Direction', 'Loss')),
      node_attr = factor(node_attr, levels = c('Decay', 'Base', ''))
    ) |>
    
    ggplot(aes(x = trial_index, y = interaction(node_type, node_attr), fill = 100*pr_max))+
    geom_tile()+
    scale_y_discrete(guide = "axis_nested")+
    labs(x = 'Hyperparameter Set', y = '', title = 'Iterative Improvement of Hyperparameters', fill = '% Max')+
    theme(panel.background = element_rect(fill = "white", colour = NA),
          axis.ticks = element_line(colour = 'gray'))
  
  return(plt)
  
}
```


```{r hyps vis 1b, eval=FALSE}
hvnn <- read_parquet('./ax_tables_vnn.parquet')
hdnn <- read_parquet('./ax_tables_dnn.parquet')

p1 <- plt_hyps_grid_vnn(filter(hvnn, exp == 'data_gmx', phn == 'phno_OilDry'))
p2 <- plt_hyps_grid_dnn(filter(hdnn, exp == 'data_gmx', phn == 'phno_OilDry'))

p1/p2


# TODO think about refactoring this so that the data prep and plotting are separate
# that could ensure the tiles are the same size.
  
#   scale_fill_viridis(
#     option = 'B'#LETTERS[]
# # #     "magma" (or "A")
# # # 
# # # "inferno" (or "B")
# # # 
# # # "plasma" (or "C")
# # # 
# # # "viridis" (or "D")
# # # 
# # # "cividis" (or "E")
# # # 
# # # "rocket" (or "F")
# # # 
# # # "mako" (or "G")
# # # 
# # # "turbo" (or "H")
# #     
#   ) +

```


```{r hyps vis 2a}
# Hyperparameters ---

hvnn <- read_parquet('./ax_tables_vnn.parquet')
hdnn <- read_parquet('./ax_tables_dnn.parquet')

hvcols = c(
  "train_loss", 
  "default_out_nodes_inp", "default_out_nodes_edge", 
  "default_drop_nodes_inp", "default_drop_nodes_edge", "default_drop_nodes_out", 
  "default_reps_nodes_inp", "default_reps_nodes_edge", "default_reps_nodes_out", 
  "default_decay_rate"#, "default_out_nodes_out"
  )
  
hdcols = c(
  "train_loss", 
  "hidden_layers", "width", "drop", 
  "width_decay_rate", "drop_decay_rate", 
  "width_decay_reverse", "drop_decay_reverse"#, 
  # "size_out",
  # "size_in"
  )


M <- full_join(
  pivot_longer(hvnn, cols = all_of(hvcols)), 
  pivot_longer(hdnn, cols = all_of(hdcols))
)
```


```{r hyps vis 2b, eval=FALSE}
# use plt_hyps for poster

plt_hyps_grid_compare <- function(
    df = filter(M, exp == "data_dme" & phn == "ADHReplicates_hzg" )
){
  plt <- df |> 
    full_join(data.frame(
      model = c(''),
      trial_index = c(NA)
      # trial_index = c(0),
    )) |>
    group_by(exp, phn, model, name) |>
    # set scaling col
    mutate(pr_max = (value - min(value))/(max(value) - min(value)) ) |>
    ungroup() |>
    mutate(
      # higher level grouping
      node_type = case_when(
        name %in% c('train_loss') ~ '',
        name %in% c( 'default_out_nodes_inp',  'default_out_nodes_edge', 'default_drop_nodes_out', 'width') ~ 'Width',
        name %in% c('default_decay_rate', 'width_decay_rate', 'width_decay_reverse') ~ 'Width',
        name %in% c('default_drop_nodes_inp', 'default_drop_nodes_edge'                          , 'drop') ~ 'Dropout',
        name %in% c('drop_decay_rate', 'drop_decay_reverse') ~ 'Dropout',
        name %in% c('default_reps_nodes_inp', 'default_reps_nodes_edge', 'default_reps_nodes_out') ~ 'Repeats',
        name %in% c('hidden_layers') ~ '',
        TRUE ~ ''
      ),
      # this is the lowest level 
      node_attr = case_when(
        name %in% c('train_loss') ~ 'Loss',    
        
        name %in% c('default_out_nodes_inp', 'default_drop_nodes_inp', 'default_reps_nodes_inp') ~ 'Input',
        name %in% c('default_out_nodes_edge', 'default_drop_nodes_edge', 'default_reps_nodes_edge') ~ 'Edge',
        
        
        name %in% c('width') ~ 'Edge',
        name %in% c('default_drop_nodes_out', 'default_reps_nodes_out') ~ 'Output',
        
        name %in% c('default_decay_rate', 'width_decay_rate',    'drop_decay_rate'   ) ~ 'Rate',      
        name %in% c(                      'width_decay_reverse', 'drop_decay_reverse') ~ 'Order',  
        name %in% c('drop') ~ 'Edge',
        name %in% c('hidden_layers') ~ 'Layers',
        
        TRUE ~ ''
      )) |>
    mutate(model = case_when(
      model == 'vnn' ~ 'VNN',
      model == 'dnn' ~ 'DNN',
      TRUE ~ ''
    )) |>
    mutate(
      model =     factor(model,     levels = c('DNN', '', 'VNN')),
      node_type = factor(node_type, levels = c('', 'Repeats', 'Dropout', 'Width')),
      node_attr = factor(node_attr, levels = c('Loss', 
                                               'Order', 'Rate', 'Base', 'Layers', 'Input', 'Edge', 'Output',
                                               ''))
    ) |>
    # ggplot(aes(x = trial_index, y = interaction(name, node_attr, node_type, model), fill = 100*pr_max))+
    ggplot(aes(x = trial_index, y = interaction(node_attr, node_type, model), fill = 100*pr_max))+
    geom_tile()+
    # facet_wrap(.~model, scales = "free", ncol = 1)
    scale_y_discrete(guide = "axis_nested")+
    labs(x = 'Hyperparameter Set', y = '', title = 'Iterative Improvement of Hyperparameters', fill = '% Max')+
    theme(panel.background = element_rect(fill = "white", colour = NA), axis.ticks = element_line(colour = 'gray'))
  
  return(plt)
  
}
```


```{r hyps vis 2c, eval=FALSE}
# use plt_hyps for poster

plt_hyps_grid_compare(df = filter(
  M, exp == "data_dme" & 
     phn == "ADHReplicates_hzg" )
  )+labs(title = '')



plt_settings <- M   |> 
  select(exp, phn)  |> 
  distinct()        |> 
  mutate(phn = factor(phn, levels = phno_iter)) |>
  arrange(exp, phn) |>
  mutate(phn = as.character(phn))



phn_clean_names <-c(
  'ADHReplicates_hzg',                   '*D. mel.* Alcohol Dehydrogenase',
  'phno_ProteinDry',                     '*G. max* Protein',  
  'phno_StachyoseDry',                   '*G. max* Stachyose',
  'phno_OilDry',                         '*G. max* Oil', 
  # 'phno_all_Pollen_GDD__WIH2_2020',      '*Z. mays* Pollen GDD (WIH2 2020)',  
  'phno_all_Pollen_GDD__FTaxaREnvRGxE',  '*Z. mays* Pollen GDD (Est.)',
  # 'phno_all_Yield_Mg_ha__IAH3_2021',     '*Z. mays* Yield Mg/ha (IAH3 2021)',
  'phno_all_Yield_Mg_ha__FTaxaREnvRGxE', '*Z. mays* Yield Mg/ha (Est.)',
  'phno_all_Yield_Mg_ha',                '*Z. mays* Yield Mg/ha (Raw)'
  )




phn_clean_names = data.frame(
  phn = phn_clean_names[seq(1, length(phn_clean_names), 2)],
  new = phn_clean_names[seq(2, length(phn_clean_names), 2)]
  )


plt_hyps_lst <- map(
  seq(1, nrow(plt_settings)), 
  function(i){
    exp_type = as.character(plt_settings[i, 'exp'])
    exp_type = str_extract(exp_type, pattern = '_....$')
    if (is.na(exp_type)){
      exp_type = ''
    } else {
      exp_type = str_remove_all(exp_type, '_')
    }
    
    plt_hyps_grid_compare(df = filter(
      M, 
      exp == as.character(plt_settings[i, 'exp']) & 
      phn == as.character(plt_settings[i, 'phn'])
    )
    )+labs(
      title = paste0(
        select(filter(
          phn_clean_names, 
          phn == as.character(plt_settings[i, 'phn'])),
          new), ' ', exp_type)
    ) + 
      theme(title = element_markdown(), 
            legend.position = 'none')
  }
)


p <- plt_hyps_lst


map(c(
  "ADHReplicates_hzg",
  "phno_ProteinDry",
  "phno_StachyoseDry",
  "phno_OilDry",
  "phno_all_Pollen_GDD__FTaxaREnvRGxE",
  "phno_all_Yield_Mg_ha__FTaxaREnvRGxE",
  "phno_all_Yield_Mg_ha"
), function(ith_phn){
  cowplot::plot_grid(plotlist = p[(
    mutate(plt_settings, n = seq(1, nrow(plt_settings))) |> filter(phn == ith_phn))$n
  ], ncol = 1)
})


# design <- "
# ADEF
# BGHI
# CJK#
# "
# 
# p[[1]]+p[[2]]+p[[3]]+p[[4]]+p[[5]]+p[[6]]+p[[7]]+p[[8]]+plot_layout(design = design)
```



```{r disregard}


# xx <-  M |> select(exp, phn) |> distinct() 
# 
# xx <- data.frame(list(
#   c("", "data_dme", "ADHReplicates_hzg"), 
#   c("", "data_dme_lsuv_relu", "ADHReplicates_hzg"),
#   c("", "data_dme_lsuv_tanh", "ADHReplicates_hzg"), 
#   c("", "data_dme_lsuv_vlin", "ADHReplicates_hzg"), 
#   c("", "data_gmx", "phno_ProteinDry"), 
#   c("", "data_gmx", "phno_StachyoseDry"), 
#   c("", "data_gmx", "phno_OilDry"), 
#   c("", "data_gmx_lsuv_relu", "phno_ProteinDry"), 
#   c("", "data_gmx_lsuv_relu", "phno_StachyoseDry"), 
#   c("", "data_gmx_lsuv_relu", "phno_OilDry"), 
#   c("", "data_gmx_lsuv_tanh", "phno_ProteinDry"), 
#   c("", "data_gmx_lsuv_tanh", "phno_OilDry"), 
#   c("", "data_gmx_lsuv_vlin", "phno_ProteinDry"), 
#   c("", "data_gmx_lsuv_vlin", "phno_StachyoseDry"), 
#   c("", "data_gmx_lsuv_vlin", "phno_OilDry"), 
#   c("", "data_zma", "phno_all_Pollen_GDD__FTaxaREnvRGxE"), 
#   c("", "data_zma", "phno_all_Yield_Mg_ha"), 
#   c("", "data_zma", "phno_all_Pollen_GDD__WIH2_2020"), 
#   c("", "data_zma", "phno_all_Yield_Mg_ha__IAH3_2021"), 
#   c("", "data_zma", "phno_all_Yield_Mg_ha__FTaxaREnvRGxE"), 
#   c("", "data_zma_lsuv_relu", "phno_all_Pollen_GDD__FTaxaREnvRGxE"), 
#   c("", "data_zma_lsuv_relu", "phno_all_Yield_Mg_ha"), 
#   c("", "data_zma_lsuv_relu", "phno_all_Yield_Mg_ha__FTaxaREnvRGxE"), 
#   c("", "data_zma_lsuv_tanh", "phno_all_Pollen_GDD__FTaxaREnvRGxE"), 
#   c("", "data_zma_lsuv_tanh", "phno_all_Yield_Mg_ha"), 
#   c("", "data_zma_lsuv_tanh", "phno_all_Yield_Mg_ha__FTaxaREnvRGxE"), 
#   c("", "data_zma_lsuv_vlin", "phno_all_Pollen_GDD__FTaxaREnvRGxE"), 
#   c("", "data_zma_lsuv_vlin", "phno_all_Yield_Mg_ha"), 
#   c("", "data_zma_lsuv_vlin", "phno_all_Yield_Mg_ha__FTaxaREnvRGxE")
# )) |> t()
# 
# xx <- data.frame(
#   new = as.vector(xx[, 1]),
#   exp = as.vector(xx[, 2]),
#   phn = as.vector(xx[, 3])  
# )
# 
# 
# xx[20:25, ]
# i = 22
# 
# 
# plt_hyps_grid_compare(df = filter(
#   M, exp == xx[i, 'exp'] & 
#      phn == xx[i, 'phn'] )
#   )+labs(title = paste(xx[i, 'phn'], xx[i, 'exp']))
```



```{r poster}
# for the poster

# Can I tune hyperparameters?


plt_hyps <- function(
    df = filter(
      M, 
      exp == 'data_zma', # "data_zma"           "data_zma_lsuv_relu" "data_zma_lsuv_tanh" "data_zma_lsuv_vlin"
      phn == "phno_all_Pollen_GDD__FTaxaREnvRGxE",
      model == 'dnn' # vnn dnn
      )
){
  plt <- df |> 
    full_join(data.frame(
      model = c(''),
      trial_index = c(NA) # spiking in a NA here and then using TRUE ~ '' in mutate below adds a spacer
    )) |>
    group_by(exp, phn, model, name) |>
    # set scaling col
    mutate(pr_max = (value - min(value))/(max(value) - min(value)) ) |>
    ungroup() |>
    # filter(!is.na(name)) |>
    mutate(
      # higher level grouping
      node_type = case_when(
        name %in% c('train_loss') ~ '',
        name %in% c( 'default_out_nodes_inp',  'default_out_nodes_edge', 'default_drop_nodes_out', 'width') ~ 'Width',
        name %in% c('default_decay_rate', 'width_decay_rate', 'width_decay_reverse') ~ 'Width',
        name %in% c('default_drop_nodes_inp', 'default_drop_nodes_edge'                          , 'drop') ~ 'Dropout',
        name %in% c('drop_decay_rate', 'drop_decay_reverse') ~ 'Dropout',
        name %in% c('default_reps_nodes_inp', 'default_reps_nodes_edge', 'default_reps_nodes_out') ~ 'Repeats',
        name %in% c('hidden_layers') ~ '',
        TRUE ~ ''
      ),
      # this is the lowest level 
      node_attr = case_when(
        name %in% c('train_loss') ~ 'Loss',    
        
        name %in% c('default_out_nodes_inp', 'default_drop_nodes_inp', 'default_reps_nodes_inp') ~ 'Input',
        name %in% c('default_out_nodes_edge', 'default_drop_nodes_edge', 'default_reps_nodes_edge') ~ 'Edge',
        
        
        name %in% c('width') ~ 'Edge',
        name %in% c('default_drop_nodes_out', 'default_reps_nodes_out') ~ 'Output',
        
        name %in% c('default_decay_rate', 'width_decay_rate',    'drop_decay_rate'   ) ~ 'Rate',      
        name %in% c(                      'width_decay_reverse', 'drop_decay_reverse') ~ 'Order',  
        name %in% c('drop') ~ 'Edge',
        name %in% c('hidden_layers') ~ 'Layers',
        
        TRUE ~ ''
      )) |>
    # select(node_type, node_attr) |> distinct()
    
    mutate(
      node_type = factor(node_type, levels = c('', 'Repeats', 'Dropout', 'Width')),
      node_attr = factor(node_attr, levels = c('Loss', '',
                                               'Order', 'Rate', 'Base', 'Layers', 'Input', 'Edge', 'Output'
                                               ))
    ) |>
    ggplot(aes(x = trial_index, y = interaction(node_attr, node_type), fill = 100*pr_max))+
    geom_tile()+
    scale_y_discrete(guide = "axis_nested")+
    labs(x = 'Hyperparameter Set', y = '', title = 'Iterative Improvement of Hyperparameters', fill = '% Max')+
    theme(panel.background = element_rect(fill = "white", colour = NA), axis.ticks = element_line(colour = 'gray'))
  
  return(plt)
  
}



xx <- list(
  c("dnn", "data_zma",           "phno_all_Pollen_GDD__FTaxaREnvRGxE", "DNN Tanh"),
  c("vnn", "data_zma",           "phno_all_Pollen_GDD__FTaxaREnvRGxE", "VNN Tanh"),
  c("vnn", "data_zma_lsuv_relu", "phno_all_Pollen_GDD__FTaxaREnvRGxE", "VNN Tanh LSUV"),
  c("vnn", "data_zma_lsuv_tanh", "phno_all_Pollen_GDD__FTaxaREnvRGxE", "VNN Relu LSUV"), 
  c("vnn", "data_zma_lsuv_vlin", "phno_all_Pollen_GDD__FTaxaREnvRGxE", "VLN LSUV") 
  )
plt_list <- map(seq_along(xx), function(i){
  plt <- plt_hyps(
    df = filter(
      M,
      model == xx[[i]][1],
      exp == xx[[i]][2],
      phn == xx[[i]][3]
      )
    )
  plt <- plt + labs(title = xx[[i]][4])
  if(i < length(xx)){
    plt <- plt + theme(legend.position = 'none')
  }
  return(plt)
})

p <- plt_list 



design <- "ABCDE"

p <- (p[[1]]+p[[2]]+p[[3]]+p[[4]]+p[[5]])+plot_layout(design = design)


ggsave('poster_0hyps_1grid.svg', p, width = 30, height = 5, units = 'in')

```






## [X] Hyps Performance

```{r}
# for poster


p <- plt_net_metrics(md = md, phase_i = 'lightning', phno_i = 'phno_all_Pollen_GDD__FTaxaREnvRGxE')
p <- p+scale_y_continuous(
        trans = "log10",
        breaks = c(0.5, 1, 10, 100, 1000)
    )+
    labs(x = '', y = '')+
  facet_grid(phno~init, labeller = labeller(
  # .default = capitalize,
  phno = c(phno_all_Pollen_GDD__FTaxaREnvRGxE = "Pollen GDD Est."),
  init = c(
    dnn.r.tanh = 'DNN Tanh',
    vnn.r.tanh = 'VNN Tanh',
    vnn.l.tanh = 'VNN Tanh LSUV',
    vnn.l.relu = 'VNN Relu LSUV',
    vnn.l.none = 'VLN LSUV'
  )
))

p

ggsave('poster_0hyps_2trace.svg', p, width = 15, height = 5, units = 'in')


```


```{r}
# plt_net_metrics(md = md, phno_i = 'phno_all_Yield_Mg_ha', phase_i = 'lightning')

plt_list <- map(phno_iter, function(ii){
  plt_net_metrics(md = md, phase_i = 'lightning', phno_i = ii)
  })


# plt_list <- map(plt_list, function(e){
#   e+scale_y_continuous(
#         trans = "log10",
#         breaks = c(0.5, 1, 10, 100, 1000)
#     )
#   })
plt_list <- map(plt_list, function(e){
  e+scale_y_continuous(
        trans = "log10",
        breaks = c(0.5, 1, 10, 100, 1000)
    )+
    labs(x = '', y = '')
  })

plt_list[[1]] <- plt_list[[1]]+
    labs(x = 'Epoch', y = 'Loss (MSE)')


p <- plt_list
names(p) <- phno_iter


design <- "
AABE
AACF
AADG
"


design <- "
AA
AA
BE
CF
DG
"

(
  p[["phno_all_Pollen_GDD__FTaxaREnvRGxE"]]+
  p[["phno_all_Yield_Mg_ha__FTaxaREnvRGxE"]]+
  p[["phno_all_Yield_Mg_ha"]]+
  p[["ADHReplicates_hzg"]]+
  p[["phno_OilDry"]]+
  p[["phno_ProteinDry"]]+
  p[["phno_StachyoseDry"]]
)+plot_layout(design = design)

```





## [X] Err. Hist.

```{r, eval=FALSE}
# Example case with vnn -- used this to figure out the above function (`plt_net_metrics`)

tmp_md <- md |> 
  filter(
    phase == 'models', 
    info == 'metrics', 
    phno == 'ADHReplicates_hzg'
    ) 

tmp_md <- tmp_md |>
  mutate(init = case_when(
    str_detect(data, 'lsuv_relu$') ~ 'l.relu',
    str_detect(data, 'lsuv_tanh$') ~ 'l.tanh',
    str_detect(data, 'lsuv_vlin$') ~ 'l.none',
    TRUE ~ 'r.tanh'
  )) 

tmp_dl <- map(tmp_md$path, function(ii){mutate(load_model_metrics(ii)$metrics, path=ii)})

tmp_dl <- full_join(tmp_md, do.call(rbind, tmp_dl) )

tmp_dl_envelope <- tmp_dl |>
  filter(model == 'vnn', split == 'trn') |>
  group_by(data, phno, model, init, split, epoch) |>
  mutate(
    min_trn = case_when(split == 'trn' ~ min(loss)),
    max_trn = case_when(split == 'trn' ~ max(loss)) )   |>
  select(-loss, -step) |>
  distinct()

tmp_dl |>
  filter(model == 'vnn', split == 'val') |>
  # group_by(data, phno, model, init, split, epoch) |>
  # mutate(loss = mean(loss)) |>
  # distinct() |>
  ggplot(aes(x = epoch, group = path))+
  geom_ribbon(data=tmp_dl_envelope, aes(ymin=min_trn, ymax=max_trn), alpha = 0.3)+
  geom_line(aes(y = loss))+
  theme_minimal()+
  # coord_cartesian(xlim = c(0, 1))+
  facet_grid(phno~init)+
  scale_y_continuous(
    trans = "log10",
    breaks = c(0.5, 1, 10, 100, 1000)
  )
```


```{r}
plt_list <- map(phno_iter, function(ii){
  plt_net_metrics(md = md, phase_i = 'models', phno_i = ii, show_min_loss = TRUE)
  })


plt_list <- map(plt_list, function(e){
  e+scale_y_continuous(
        trans = "log10",
        breaks = c(0.5, 1, 10, 100, 1000)
    )+
    labs(x = '', y = '')
  })

plt_list[[1]] <- plt_list[[1]]+
    labs(x = 'Epoch', y = 'Loss (MSE)')


p <- plt_list
names(p) <- phno_iter


design <- "
AABE
AACF
AADG
"

(
  p[["ADHReplicates_hzg"]]+
  p[["phno_OilDry"]]+
  p[["phno_ProteinDry"]]+
  p[["phno_StachyoseDry"]]+ 
  p[["phno_all_Pollen_GDD__FTaxaREnvRGxE"]]+
  p[["phno_all_Yield_Mg_ha__FTaxaREnvRGxE"]]+
  p[["phno_all_Yield_Mg_ha"]]
)+plot_layout(design = design)
```


```{r}
# for poster


p <- plt_net_metrics(md = md, phase_i = 'models', phno_i = 'phno_all_Pollen_GDD__FTaxaREnvRGxE', show_min_loss = TRUE)
p <- p+scale_y_continuous(
        trans = "log10",
        breaks = c(0.5, 1, 10, 100, 1000)
    )+
    labs(x = 'Epoch', y = 'Loss (MSE)')+
  facet_grid(phno~init, labeller = labeller(
  # .default = capitalize,
  phno = c(phno_all_Pollen_GDD__FTaxaREnvRGxE = "Pollen GDD Est."),
  init = c(
    dnn.r.tanh = 'DNN Tanh',
    vnn.r.tanh = 'VNN Tanh',
    vnn.l.tanh = 'VNN Tanh LSUV',
    vnn.l.relu = 'VNN Relu LSUV',
    vnn.l.none = 'VLN LSUV'
  )
))

p

ggsave('poster_1mods_2trace.svg', p, width = 15, height = 5, units = 'in')
```

## [_] Err. Prediction



```{r}
md$model |> unique()

md |> 
  filter(model == 'lin') |>
  select(info) |> 
  distinct()

md |>
  filter(
    data == 'data_dme', 
    phno == 'ADHReplicates_hzg',
    model == 'lin', 
    info == 'bWGR_yhat'
    )

tmp <- read_parquet('../data_dme/ADHReplicates_hzg/lin/models/blup/403fe023ad_bWGR_yhat.parquet')

mean((tmp[, 2] - tmp[, 3])**2)

names(tmp) <- c('Taxa', 'Obs', 'YHat', 'Split')

tmp_cs <- tmp |> 
  filter(Split == 'train') |>
  summarise(
    c = mean(Obs), 
    s = sd(Obs)
    )


tmp |>
  mutate(YHat = ((YHat * tmp_cs$s) + tmp_cs$c)) |>
  ggplot(aes(x=Obs, y=YHat))+
  geom_point()+
  geom_smooth()+
  facet_grid(.~Split)


tmp |>
  mutate(YHat = ((YHat * tmp_cs$s) + tmp_cs$c)) |>
  group_by(Split) |>
  summarise(MSE = mean((Obs - YHat)**2))

```



```{r}
# # md
# phase_i = 'models' # always
# phno_i = 'ADHReplicates_hzg'
# # show_min_loss
# 
# md |>
#   filter(
#     # data == 'data_dme', 
#     phno == phno_i,
#     model == 'lin', 
#     info == 'bWGR_yhat'
#     )
# 
# phno_iter
# 
# "ADHReplicates_hzg"                   "phno_all_Pollen_GDD__FTaxaREnvRGxE"  "phno_all_Yield_Mg_ha"               
# [4] "phno_all_Yield_Mg_ha__FTaxaREnvRGxE" "phno_OilDry"                         "phno_ProteinDry"                    
# [7] "phno_StachyoseDry"
# 
# phno_i = 'phno_all_Yield_Mg_ha'



get_final_loss <- function(md, phno_i, phase_i = 'models'){
  # This is the same start as `plt_net_metrics` but 
  # 1. I filter to the final observations and 
  # 2. I collect values from the linear models.
  
  tmp_md <- md |> 
    filter(
      phase == phase_i, 
      info == 'metrics', 
      phno == phno_i
    ) 
  
  tmp_md <- tmp_md |>
    mutate(init = case_when(
      str_detect(data, 'lsuv_relu$') ~ 'l.relu',
      str_detect(data, 'lsuv_tanh$') ~ 'l.tanh',
      str_detect(data, 'lsuv_vlin$') ~ 'l.none',
      TRUE ~ 'r.tanh'
    )) 
  
  # tmp_dl <- map(tmp_md$path, function(ii){mutate(load_model_metrics(ii)$metrics, path=ii)})
  tmp_dl <- map(tmp_md$path, function(ii){
    x <- mutate(load_model_metrics(ii)$metrics, path=ii)
    x <- filter(x, epoch == max(epoch))
    x$mini_batch <- seq(1, nrow(x))
    return(x)
    })
    
  tmp_dl <- full_join(tmp_md, do.call(rbind, tmp_dl) )
  
  # NOTE without modificaiton to the init field it's best to filter the records
  # tmp_dl <- tmp_dl |> filter(model == 'vnn')
  tmp_dl <- tmp_dl |> 
    mutate(init = paste0(model, '.', init)) 
  
  
  tmp_dl <- full_join(
    tmp_dl, 
    expand.grid(
      phno = phno_i,
      split = c('trn', 'val'),
      init = c(
        'dnn.r.tanh', 
        'vnn.r.tanh', 
        'vnn.l.tanh', 
        'vnn.l.relu',
        'vnn.l.none'
    )
    )) |>  
    mutate(init = factor(init, levels = c(
      'dnn.r.tanh', 
      'vnn.r.tanh', 
      'vnn.l.tanh', 
      'vnn.l.relu',
      'vnn.l.none'
    )))
  
  # tmp_dl
  # == == == == #  
  tmp_md <- md |> 
    filter(
      phase == phase_i, 
      info == 'bWGR_yhat', 
      phno == phno_i, 
      model == 'lin'
    ) 
  
  load_bWGR_yhat <- function(
      path = '../data_dme/ADHReplicates_hzg/lin/models/blup/403fe023ad_bWGR_yhat.parquet'
  ){
    metrics <- read_parquet(path)
    names(metrics) <- c('taxa', 'obs', 'yhat', 'split')
    # set yhat to be a vector instead of a 1d matrix to prevent it showing as 
    # yhat[,1] in the tibble header
    metrics$yhat <- as.vector(metrics$yhat)
    metrics <- metrics |> 
      mutate(split = case_when(
        split == 'train' ~ 'trn', 
        split == 'test'  ~ 'val'
      ))
    return(metrics)
  }
  
  tmp_lm <- map(tmp_md$path, function(ii){mutate(load_bWGR_yhat(ii), path=ii)})
  
  tmp_lm <- full_join(tmp_md, do.call(rbind, tmp_lm) )
  
  tmp_lm <- tmp_lm |> 
    mutate(init = 'none') |> 
    mutate(init = paste0(model, '.', init)) 
  
  
  # Are the values in tmp_lm centered and scaled? 
  # It looks like they are not:
  # tmp_lm |>
  #   group_by(path, split) |>
  #   summarise(
  #     o_c = mean(obs),
  #     o_s = sd(obs),
  #     y_c = mean(yhat),
  #     y_s = sd(yhat)
  #     ) |>
  #   arrange(split, path)
  # 
  
  # # A tibble: 12 Ã— 6
  # # Groups:   path [6]
  #    path                                                                     split   o_c   o_s   y_c   y_s
  #    <chr>                                                                    <chr> <dbl> <dbl> <dbl> <dbl>
  #  1 ../data_gmx/phno_ProteinDry/lin/models/blup/361ee2ff57_bWGR_yhat.parquet trn    44.2  2.21  44.2  1.55
  #  2 ../data_gmx/phno_ProteinDry/lin/models/blup/58d298935f_bWGR_yhat.parquet trn    44.2  2.24  44.2  1.57
  #  3 ../data_gmx/phno_ProteinDry/lin/models/blup/656a758935_bWGR_yhat.parquet trn    44.2  2.21  44.2  1.52
  #  4 ../data_gmx/phno_ProteinDry/lin/models/blup/6e08bcfa2b_bWGR_yhat.parquet trn    44.1  2.26  44.1  1.64
  #  5 ../data_gmx/phno_ProteinDry/lin/models/blup/7c2d03c704_bWGR_yhat.parquet trn    44.2  2.22  44.2  1.55
  #  6 ../data_gmx/phno_ProteinDry/lin/models/blup/8132724e66_bWGR_yhat.parquet trn    44.2  2.24  44.2  1.56
  #  7 ../data_gmx/phno_ProteinDry/lin/models/blup/361ee2ff57_bWGR_yhat.parquet val    44.1  2.40  43.8  2.07
  #  8 ../data_gmx/phno_ProteinDry/lin/models/blup/58d298935f_bWGR_yhat.parquet val    43.7  1.82  43.4  1.37
  #  9 ../data_gmx/phno_ProteinDry/lin/models/blup/656a758935_bWGR_yhat.parquet val    44.3  2.49  44.3  2.03
  # 10 ../data_gmx/phno_ProteinDry/lin/models/blup/6e08bcfa2b_bWGR_yhat.parquet val    44.6  2.10  44.5  1.55
  # 11 ../data_gmx/phno_ProteinDry/lin/models/blup/7c2d03c704_bWGR_yhat.parquet val    44.2  2.21  44.3  1.12
  # 12 ../data_gmx/phno_ProteinDry/lin/models/blup/8132724e66_bWGR_yhat.parquet val    44.3  1.77  44.1  1.48  
  
  # so I need to cs the data before reporting it
  tmp_lm <- left_join(
    tmp_lm, 
    (
      tmp_lm |>
        filter(split == 'trn') |>
        group_by(path) |>
        summarise(o_c = mean(obs), o_s = sd(obs)) 
     )
  )
  
  # center and scale and then reduce down to mse
  tmp_lm <- tmp_lm |> 
    ungroup() |>
    mutate(
      obs = ((obs - o_c) / o_s),
      yhat= ((yhat- o_c) / o_s), 
      ) |>
    group_by(path, split) |>
    mutate(mse = mean((obs - yhat)**2) ) |>
    select(-taxa, -obs, -yhat, -o_c, -o_s) |>
    distinct()

  
  tmp_lm
  
  # FIXME - doesn't need a fix but should be aware of this
  # NOTE this is not going to be exactly the same as the error calculated from 
  # the predictions because 
  # 1. we have mini batches of (potentially) unequal size
  # 2. we have mini batches calculated in _training_ mode.  
  # The upside to running this is that we don't need to do the full prediction 
  # set before getting a sense of which are good/bad models.

  tmp_dl <- tmp_dl |>
    select(-epoch, -step, -mini_batch) |>
    group_by(path, split) |>
    mutate(loss = mean(loss)) |>
    distinct()
  
  
  tmp_all <- full_join(
    (tmp_lm |> 
       ungroup() |>
       select(data, phno, model, phase, 
              # version, info, path, hash, 
              split, init, mse)),
    (tmp_dl |>
       ungroup() |>
       select(data, phno, model, phase, 
              # version, info, path, hash, 
              split, init, loss) |>
       rename(mse = loss))
  )
  
  
  return(tmp_all)
}


tmp_all <- get_final_loss(
  md = md, 
  phno_i = 'phno_all_Yield_Mg_ha__FTaxaREnvRGxE', 
  phase_i = 'models'
  )

tmp_all <- tmp_all |> 
  mutate(init = case_when(
    init == "lin.none" ~ "BLUP",
    init == "vnn.r.tanh" ~ "VNN Tanh",
    init == "dnn.r.tanh" ~ "DNN Tanh",
    init == "vnn.l.relu" ~ "VNN Relu LSUV",
    init == "vnn.l.tanh" ~ "VNN Tanh LSUV",
    init == "vnn.l.none" ~ "VLN LSUV"
  )) |>
  mutate(init = factor(
    init, 
    c("BLUP", "DNN Tanh", "VNN Tanh", "VNN Tanh LSUV", "VNN Relu LSUV", "VLN LSUV") 
  ))



tmp_all |>



p_top <- tmp_all |> 
  ggplot(aes(x = init, y = mse, fill = split))+
  geom_boxplot()+
  geom_point(position = position_dodge(width=0.751) )+
  scale_fill_manual(values = c('cornflowerblue', 'orange') )+
  labs(x = '', y = '')+
  theme_minimal()+
  theme(axis.text.x = element_blank())+
  coord_cartesian(ylim = c(10, 4100))+
  scale_y_log10()


tmp_all |> 
  ggplot(aes(x = init, y = mse, fill = split))+
  geom_boxplot()+
  geom_point(position = position_dodge(width=0.751) )+
  scale_fill_manual(values = c('cornflowerblue', 'orange') )+
  labs(x = '', y = 'MSE')+
  theme_minimal()+
  coord_cartesian(ylim = c(0, 1.5))
  



    

```


## [_] Predictions
```{r}
## New functions:


pred_parquet_to_df <- function(paths = unlist(mdi[, 'path']), model_type = 'dnn'){
  ## Turn output into a single table
  res_l <- map(paths, function(ij_path){ 
    read_parquet(ij_path) 
  })
  
  res_l <- map(seq_along(res_l), function(i){
    e <- res_l[[i]]
    names(e) <- tolower(names(e))
    e <- e |> mutate(join_this = TRUE)
    return(e)
  })
  names(res_l) <- as.vector(unlist(mdi[, 'info']))
  
  # BLUP output
  if(model_type == 'lin'){
    if(assertthat::are_equal(length(res_l), 1)){
      res <- res_l[[1]]
      res$yhat <- as.vector(res$yhat)
      names(res)[2] <- 'obs'
      res <- res |>
        select(-join_this) |>
        select(taxa, split, obs, yhat)
    }
  } else {
    # [vd]nn output
    # update names so these tables merge nicely
    names(res_l$yvar_cs_center)[1] <- 'yvar_mu'
    names(res_l$yvar_cs_scale)[1]  <- 'yvar_sd'
    
    names(res_l$yhat_trn)[1] <- 'yhat'
    names(res_l$yhat_val)[1] <- 'yhat'
    
    names(res_l$yhat_cs_trn)[1] <- 'yhat_cs'
    names(res_l$yhat_cs_val)[1] <- 'yhat_cs'
    
    names(res_l$yvar_cs_trn)[1] <- 'obs_cs'
    names(res_l$yvar_cs_val)[1] <- 'obs_cs'
    
    res <- full_join(res_l$yvar_cs_center, res_l$yvar_cs_scale) |>
      full_join(rbind(res_l$yhat_trn,    res_l$yhat_val   )) |>
      full_join(rbind(res_l$yhat_cs_trn, res_l$yhat_cs_val)) |>
      full_join(rbind(res_l$yvar_cs_trn, res_l$yvar_cs_val)) |>
      select(-join_this) |>
      select(taxa, phno_idx, split, obs_cs, yvar_mu, yvar_sd, yhat, yhat_cs)
    
  }
  return(res)
}

# since I can't use do.call with full_join, here's a work around
full_join_list <- function(lst){
  for(i in seq_along(lst)){
    if(i == 1){
      out <- lst[[i]]
    } else {
      out <- full_join(out, lst[[i]])
    }
  }
  return(out)
}



## Processing:


# md
phase_i = 'models' # always
phno_i = 'phno_all_Pollen_GDD__FTaxaREnvRGxE'
# show_min_loss


md1 <- md |>
  filter(
    phno == phno_i,
    phase == phase_i,
    # don't use model history or evaluation
    (stringr::str_detect(info, 'eval_', negate = T) & (info != 'metrics')) 
    ) |>
  select(-phno, -phase, -version)

# process each data:model:hash
# here are the blocks of files I need to opperate over.
md1_blocks <- md1 |> 
  select(model, data, hash) |> 
  distinct() |>
  mutate(model = factor(model, levels = c('lin', 'dnn', 'vnn'))) |>
  arrange(model, data, hash) |>
  mutate(model = as.character(model))



out_l <- list()
for(i in seq(1, nrow(md1_blocks))){
  mdi <- left_join(md1_blocks[i, ], md1)
  out <- cbind(
    md1_blocks[i, ],
    pred_parquet_to_df(
      paths = unlist(mdi[, 'path']), 
      model_type = unique(unlist(mdi[, 'model']))
    )
  )
  out_l[[(length(out_l)+1)]] <- out
}

out <- full_join_list(lst = out_l)


out <- out |> 
  mutate(
  split = case_when(
    split %in% c('train', 'Training') ~ 'trn', 
    split %in% c('test', 'Validation') ~ 'val' 
    )
)




# can I use the information in out to get a reasonable estimate of error for all?

out |>
  filter(
    model == 'lin',
    data == 'data_zma',
    hash == '186490dd78',
    split == 'val'
  ) |>
  summarise(mse = mean((obs - yhat)**2))
  

mse_summary_lin <- out |>
  filter(model == 'lin') |>
  mutate(SE = (obs - yhat)**2 ) |>
  group_by(model, data, hash, split) |>
  filter(!is.na(SE)) |>
  summarise(MSE = mean(SE))
  

out |>
  filter(
    model != 'lin',
    data == 'data_zma',
    # hash == '186490dd78',
    split == 'val'
  ) |> 
  # mutate(yhat_rmcs =( (yhat_cs * yvar_sd) + yvar_mu)) # sanity check worked :)
  mutate(obs_rmcs =( (obs_cs * yvar_sd) + yvar_mu))


mse_summary_dnn <- out |>
  filter(model != 'lin') |>
  mutate(obs_rmcs =( (obs_cs * yvar_sd) + yvar_mu)) |>
  mutate(SE = (obs_rmcs - yhat)**2 ) |>
  group_by(model, data, hash, split) |>
  filter(!is.na(SE)) |>
  summarise(MSE = mean(SE))


M <- rbind(mse_summary_lin, mse_summary_dnn)

M |> 
  ggplot(aes(x = interaction(model, data), y = MSE, color = split))+
  geom_boxplot()+
  geom_point()+
  scale_y_log10()










# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# prefix <- '../data_zma/phno_all_Yield_Mg_ha/vnn/models/vnn/version_0/0e9a1cb339'
# 
# blup <- read_parquet(paste0(prefix, '_bWGR_yhat.parquet'))
# 
# yhat_cs_trn   <- read_parquet(paste0(prefix, '_yhat_cs_trn.parquet'))
# yhat_cs_val   <- read_parquet(paste0(prefix, '_yhat_cs_val.parquet'))
# yhat_val      <- read_parquet(paste0(prefix, '_yhat_val.parquet'))
# 
# 
# 
# yvar_cs_trn   <- read_parquet(paste0(prefix, '_yvar_cs_trn.parquet'))
# yvar_cs_val   <- read_parquet(paste0(prefix, '_yvar_cs_val.parquet'))
# 
# yvar_cs_scale <- read_parquet(paste0(prefix, '_yvar_cs_scale.parquet'))
# yvar_cs_center<- read_parquet(paste0(prefix, '_yvar_cs_center.parquet'))
# 
# yvar_trn      <- read_parquet(paste0(prefix, '_yvar_trn.parquet'))
# yvar_val      <- read_parquet(paste0(prefix, '_yvar_val.parquet'))
# 
# 
# head((yvar_trn$Yield_Mg_ha * yvar_cs_scale$Yield_Mg_ha) + yvar_cs_center$Yield_Mg_ha )
# 
# 
# plot(yvar_cs_trn$Yield_Mg_ha, yvar_trn$Yield_Mg_ha)
# 
# 
# 
# 
# 
# # plt_net_metrics <- function(md, phno_i, phase_i, show_min_loss = FALSE){
# md |>
#   filter(
#     data == 'data_zma',
#     phno == phno_i,
#     # model == 'lin',
#     model == 'vnn',
#     phase == phase_i,
#     version == 'version_0'
#     # info == 'bWGR_yhat'
#     ) |>
#   select(path)


  
```


## [_] Interpretation
```{r}
phno_i



x <- list.files('../data_zma_lsuv_tanh/phno_all_Pollen_GDD__FTaxaREnvRGxE/vnn/models/vnn/version_0/')
x <- x[str_detect(x, 'eval')]
x <- x[str_detect(x, 'parquet')]

prefix <- '../data_zma_lsuv_tanh/phno_all_Pollen_GDD__FTaxaREnvRGxE/vnn/models/vnn/version_0/da6512e68f'


gradients_nodewise_bias    <- read_parquet(paste0(prefix, '_eval_gradients_nodewise_bias.parquet'))
gradients_nodewise_weights <- read_parquet(paste0(prefix, '_eval_gradients_nodewise_weights.parquet'))
rho_nodewise_trn           <- read_parquet(paste0(prefix, '_eval_rho_nodewise_trn.parquet'))
rho_nodewise_val           <- read_parquet(paste0(prefix, '_eval_rho_nodewise_val.parquet'))
salience_genewise_trn      <- read_parquet(paste0(prefix, '_eval_salience_genewise_trn.parquet'))
salience_genewise_val      <- read_parquet(paste0(prefix, '_eval_salience_genewise_val.parquet'))
salience_snpwise_trn       <- read_parquet(paste0(prefix, '_eval_salience_snpwise_trn.parquet'))
salience_snpwise_val       <- read_parquet(paste0(prefix, '_eval_salience_snpwise_val.parquet'))

```







# Model History 

```{r}
load_model_metrics <- function(
    path = '../data_gmx_lsuv_tanh/phno_OilDry/vnn/models/vnn/version_0/metrics.csv',
    tidy = T
){
  metrics <- read_csv(path)
  if(tidy == TRUE){
    metrics <- rbind(
      
      (metrics |>
         select(-val_loss) |>
         drop_na() |>
         mutate(split = 'trn', loss = train_loss )|>
         select(-train_loss)),
      
      (metrics |>
         select(-train_loss) |>
         drop_na() |>
         mutate(split = 'val', loss = val_loss )|>
         select(-val_loss))
    )
  }
  return(
    list(
      metrics=metrics
    ))      
}


# Make a dataframe with metadata for the files I want to work with:

md <- data.frame(path = system("find ../data_* -name metrics.csv", intern = T))
md <- md |> 
  separate_wider_delim(
    path, 
    "/", 
    names = c("drp1", "data", "phno", "model", "phase", "drp2", "version"), 
    too_many = "drop", 
    cols_remove = F
    ) |> 
  select(-drp1, -drp2)


# Drop phenotypes that we're ignoring going forward
md <- md |> 
  filter(!(phno %in% c("phno_all_Pollen_GDD__WIH2_2020", 
                       "phno_all_Yield_Mg_ha__IAH3_2021")))


 

# describe the data available
md |> 
  unite(data, data:phno, sep = ':') |>
  unite(model, model:phase, sep = ':') |>
  group_by(data, model) |>
  # group_by(data, model, phase) |> 
  tally() |>
  pivot_wider(id_cols = data, names_from = model, values_from = n) |>
  print(n = 30)


vnn_model_paths <- md |> 
  filter(model == 'vnn', phase == 'models') |>
  select(path)

vnn_model_metrics <- map(
  vnn_model_paths$path, 
  function(pth){
    tmp <- load_model_metrics(path = pth)$metrics |> mutate(path = pth)
  return(tmp)
})


vnn_model_metrics <- do.call(rbind, vnn_model_metrics)

vnn_model_metrics <- left_join(
  vnn_model_metrics,
  md
)



vnn_model_metrics |>
  select(epoch, step, split, loss, data, phno, version) |>
  mutate(data = case_when(
    str_detect(data, '.+lsuv_tanh$') ~ 'lsuv_tanh',
    str_detect(data, '.+lsuv_relu$') ~ 'lsuv_relu',
    TRUE ~ 'tanh'
    )) |>
  filter(split == 'val') |>
  group_by(epoch, step, split, data, phno, version) |>
  mutate(loss_mean = mean(loss)) |>
  ggplot(aes(x = epoch, y = loss_mean, color = data, group = version))+
  geom_line()+
  facet_grid(phno~data)+
  coord_cartesian(ylim = c(0, 2))+
  theme_minimal()




vnn_model_metrics |>
  select(epoch, step, split, loss, data, phno, version) |>
  mutate(data = case_when(
    str_detect(data, '.+lsuv_tanh$') ~ 'lsuv_tanh',
    str_detect(data, '.+lsuv_relu$') ~ 'lsuv_relu',
    TRUE ~ 'tanh'
    )) |>
  filter(split != 'val') |>
  group_by(epoch, step, split, data, phno, version) |>
  mutate(loss_mean = mean(loss)) |>
  ggplot(aes(x = epoch, y = loss_mean, color = split, group = interaction(split, version)))+
  geom_line()+
  facet_grid(phno~data)+
  coord_cartesian(ylim = c(0, 2))+
  theme_minimal()
```


# Interpretation 
## Predictions
```{r}


md <- data.frame(path = c(system("find ../data_* -name '*_y[hv]a[tr]_*parquet'", intern = T)))

md <- md |> 
  separate_wider_delim(
    path, 
    "/", 
    names = c("drp1", "data", "phno", "model", "phase", "drp2", "version", "file"), 
    too_many = "drop", 
    cols_remove = F
    ) |> 
  select(-drp1, -drp2)

md <- md |> 
  separate_wider_delim(
    file, 
    "_", 
    names = c("hash", "info"), 
    too_many = "merge",
    cols_remove = T
    ) |> 
  select(-hash) |>
  separate_wider_delim(
    info, 
    ".", 
    names = c("info", "rm"), 
    too_many = "merge",
    cols_remove = T
    ) |> 
  select(-rm) |>
  separate_wider_delim(
    info,
    "_",
    names = c("variable", "info"),
    too_many = "merge",
    cols_remove = T
    ) |>
  distinct()


md |> 
  filter(
  data == 'data_dme',
  phno == 'ADHReplicates_hzg',
  model == 'vnn',
  phase == 'models',
  version == 'version_4'
) |> 
  select(path)



y_xb <- read_parquet('../data_dme/ADHReplicates_hzg/vnn/models/vnn/version_4/63dde66321_yvar_cs_center.parquet')$AdjADHSlope
y_sd <- read_parquet('../data_dme/ADHReplicates_hzg/vnn/models/vnn/version_4/63dde66321_yvar_cs_scale.parquet')$AdjADHSlope

yh_cs <- read_parquet('../data_dme/ADHReplicates_hzg/vnn/models/vnn/version_4/63dde66321_yhat_cs_val.parquet') |> rename(yh_cs = AdjADHSlope)
yh    <- read_parquet('../data_dme/ADHReplicates_hzg/vnn/models/vnn/version_4/63dde66321_yhat_val.parquet')    |> rename(yh = AdjADHSlope)
yv_cs <- read_parquet('../data_dme/ADHReplicates_hzg/vnn/models/vnn/version_4/63dde66321_yvar_cs_val.parquet') |> rename(yv_cs = AdjADHSlope)
yv    <- read_parquet('../data_dme/ADHReplicates_hzg/vnn/models/vnn/version_4/63dde66321_yvar_val.parquet')    |> rename(yv = AdjADHSlope)


M <- full_join(
  full_join(yh, yv),
  full_join(yh_cs, yv_cs)
  ) |>
  select(Split, Phno_Idx, Taxa, yh, yv, yh_cs, yv_cs)


M |>
  pivot_longer(cols = c(yh, yv, yh_cs)) |>
  ggplot(aes(yv_cs, value))+
  geom_point()+
  facet_wrap(.~name)


M |> 
  select(yh, yv, yh_cs, yv_cs) |> 
  corrr::correlate()


M |>
  ggplot(aes(x = yv_cs, y = yh_cs))+
  geom_point()







# M <- read_parquet('../data_dme/ADHReplicates_hzg/lin/models/blup/004100e7c1_bWGR_b.parquet')
# M <- read_parquet('../data_dme/ADHReplicates_hzg/lin/models/blup/004100e7c1_bWGR_cxx.parquet')
# M <- read_parquet('../data_dme/ADHReplicates_hzg/lin/models/blup/004100e7c1_bWGR_d.parquet')
# M <- read_parquet('../data_dme/ADHReplicates_hzg/lin/models/blup/004100e7c1_bWGR_mu.parquet')
# M <- read_parquet('../data_dme/ADHReplicates_hzg/lin/models/blup/004100e7c1_bWGR_Vb.parquet')
# M <- read_parquet('../data_dme/ADHReplicates_hzg/lin/models/blup/004100e7c1_bWGR_Ve.parquet')


M <- read_parquet('../data_dme/ADHReplicates_hzg/lin/models/blup/004100e7c1_bWGR_yhat.parquet')

M |>
  ggplot(aes(x = AdjADHSlope, y = yhat))+
  geom_point()


# M <- read_csv('../data_dme/ADHReplicates_hzg/lin/models/gwas/GAPIT.Association.Filter_GWAS_results.csv')

M <- read_csv('../data_dme/ADHReplicates_hzg/lin/models/gwas/GAPIT.Association.GWAS_Results.BLINK.AdjADHSlope.csv')
# M <- read_csv('../data_dme/ADHReplicates_hzg/lin/models/gwas/GAPIT.Association.GWAS_StdErr.BLINK.AdjADHSlope.csv')
# M <- read_csv('../data_dme/ADHReplicates_hzg/lin/models/gwas/GAPIT.Association.Manhattans_Symphysic_Traitsnames.csv')
# 
# M <- read_csv('../data_dme/ADHReplicates_hzg/lin/models/gwas/GAPIT.Association.PVE.BLINK.AdjADHSlope.csv')
# M <- read_csv('../data_dme/ADHReplicates_hzg/lin/models/gwas/GAPIT.Association.Vairance_markers.BLINK.AdjADHSlope.csv')
# 
# M <- read_csv('../data_dme/ADHReplicates_hzg/lin/models/gwas/GAPIT.Genotype.Distance.Rsquare.csv')
# M <- read_csv('../data_dme/ADHReplicates_hzg/lin/models/gwas/GAPIT.Genotype.Frequency_MAF.csv')
# 
# M <- read_csv('../data_dme/ADHReplicates_hzg/lin/models/gwas/GAPIT.Genotype.PCA_eigenvalues.csv')
# M <- read_csv('../data_dme/ADHReplicates_hzg/lin/models/gwas/GAPIT.Genotype.PCA.csv')


M |>
  mutate(nlogp = -log(`H&B.P.Value`)) |>
  ggplot(aes(x=nlogp))+
  geom_density()

M2 <- M |>
  mutate(nlogp = -log(`H&B.P.Value`)) |>
  filter(nlogp > 1.9) |> 
  arrange(Chr, desc(Pos))

M2$Pos_i <- seq(1, nrow(M2))
  

M2 |>  
  ggplot(aes(x=Pos_i, y=nlogp, color = Chr))+
  geom_point()

```


## Evaluation
```{r}
md <- data.frame(path = c(system("find ../data_* -name '*_eval_*parquet'", intern = T)))

md <- md |> 
  separate_wider_delim(
    path, 
    "/", 
    names = c("drp1", "data", "phno", "model", "phase", "drp2", "version", "file"), 
    too_many = "drop", 
    cols_remove = F
    ) |> 
  select(-drp1, -drp2)

md <- md  |> 
  separate_wider_delim(
    file, 
    "_", 
    names = c("hash", "info"), 
    too_many = "merge",
    cols_remove = T
    ) |> 
  select(-hash) |>
  separate_wider_delim(
    info, 
    ".", 
    names = c("info", "rm"), 
    too_many = "merge",
    cols_remove = T
    ) |> 
  select(-rm) |>
  distinct()


md |> select(info) |> distinct() |> arrange(info)

# 1 eval_gradients_nodewise_bias   
# 2 eval_gradients_nodewise_weights
# 3 eval_rho_nodewise_trn          
# 4 eval_rho_nodewise_val          
# 5 eval_salience_genewise_trn     
# 6 eval_salience_genewise_val     
# 7 eval_salience_snpwise_trn      
# 8 eval_salience_snpwise_val

md |> 
  filter(model == 'vnn', phase == 'models', info == 'eval_salience_genewise_val') |>
  select(path)



# let's do some examples
## Salience
### SNPwise
M <- read_parquet('../data_dme/ADHReplicates_hzg/vnn/models/vnn/version_4/63dde66321_eval_salience_snpwise_val.parquet')

M <- M |> 
  mutate(pos = as.numeric(pos)) |>
  arrange(chrom, pos)

M$pos_i <- seq(1, nrow(M))

M |>
  group_by(chrom) |> 
  ungroup() |>
  ggplot(aes(pos_i, salience, color = chrom))+
  geom_point()

### Genewise
M <- read_parquet('../data_dme/ADHReplicates_hzg/vnn/models/vnn/version_4/63dde66321_eval_salience_genewise_val.parquet') 
M <- M |> 
  mutate(pos = as.numeric(pos)) |>
  arrange(chrom, pos)

M$pos_i <- seq(1, nrow(M))

M |>
  group_by(chrom) |> 
  ungroup() |>
  ggplot(aes(pos_i, salience, color = chrom))+
  geom_point()


# show the top few hits
left_join(
  (filter(M, salience > quantile(M$salience, .95)) |> select(pos) |> distinct()), 
  M
  ) |>
  group_by(pos) |>
  filter(row_number() == 1) |>
  ungroup() |>
  arrange(salience) |>
  select(salience, cxn)


## Gradients Nodes
M_gb <- read_parquet('../data_dme/ADHReplicates_hzg/vnn/models/vnn/version_4/63dde66321_eval_gradients_nodewise_bias.parquet')
M_gw <- read_parquet('../data_dme/ADHReplicates_hzg/vnn/models/vnn/version_4/63dde66321_eval_gradients_nodewise_weights.parquet')

M_gwb <- full_join(
  (select(M_gb, layer, k, val_bias_grads)   |> group_by(layer, k) |> 
     mutate(val_bias_grads = max(abs(val_bias_grads))) |> distinct()),
  (select(M_gw, layer, k, val_weight_grads) |> group_by(layer, k) |> 
     mutate(val_weight_grads = max(abs(val_weight_grads))) |> distinct())
)

M_gwb |>
  filter(k != 'yhat') |>
  ggplot(aes(x = val_bias_grads, y = val_weight_grads))+
  geom_point()

M_gwb |>
  arrange(desc(val_weight_grads)) |>
  head(20)
  
  
## Correlation
M_rho <- read_parquet('../data_dme/ADHReplicates_hzg/vnn/models/vnn/version_4/63dde66321_eval_rho_nodewise_val.parquet')
M_rho <- M_rho |> drop_na()

M_rho <- left_join(
  M_rho, 
  rename(distinct(select(M_gwb, layer, k)), node = k)
)

M_rho <- M_rho |>
  mutate(absAdjADHSlope = abs(AdjADHSlope))

ggplot(data = M_rho, aes(x = layer, y = absAdjADHSlope))+
  geom_violin(aes(group = layer))+
  geom_point(data = filter(M_rho, layer > 0))


M_rho |> 
  select(layer, node_forward_idx, node, absAdjADHSlope) |>
  group_by(node) |>
  mutate(absAdjADHSlope = max(absAdjADHSlope)) |>
  distinct() |>
  ungroup() |>
  mutate(qthresh = quantile(absAdjADHSlope, .99)) |>
  filter(absAdjADHSlope >= qthresh) |>
  select(-qthresh) |>
  arrange(desc(absAdjADHSlope))
  


```













# Metrics

```{r}
metrics <- read_parquet('./metrics.parquet')

# annotate metrics with the best trial col
metrics <- metrics |> 
  separate(version, c(NA, "trial_index")) |>
  mutate(trial_index = as.numeric(trial_index)) |>
  full_join(
    rbind(
      select(hvnn, exp, phn, model, phase, trial_index, best_trial),
      select(hdnn, exp, phn, model, phase, trial_index, best_trial)
    )
  ) |>
  mutate(best_trial = case_when(best_trial == TRUE ~ TRUE, 
                                TRUE ~ FALSE))


# update naming slightly:
metrics <- metrics |>
  filter(!is.na(split)) |>
  mutate(split = case_when(split == 'train' ~ 'Train', 
                           split == 'val' ~ 'Validation'),
         model = case_when(model == 'vnn' ~ 'VNN', 
                           model == 'dnn' ~ 'DNN')
  )


tmp <- metrics |>
  filter(
    exp == 'data_dme',
    phn == 'ADHReplicates_hzg',
    # phase == 'lightning'
    # phase == 'models'
    # model == 'vnn',
    # phase == 'models',
    # split == 'train',
  ) |>
  mutate(phase = case_when(
    phase == 'lightning' ~ 'Tuning', 
    phase == 'models' ~ 'Training'
    )) |>
  mutate(phase = factor(
    phase, 
    levels = c('Tuning', 'Training')
    )) |>
  
  group_by(exp, phn, model, phase, split, trial_index, epoch) |>
  mutate(loss = mean(loss)) |>
  select(-step) |>
  distinct()

ggplot(
  filter(tmp, best_trial == FALSE #& model == 'VNN'
  ), 
  aes(x = epoch, y = loss, group = trial_index ))+
  geom_line(aes(color=best_trial), color = '#99999955')+
  geom_line(data = filter(tmp, best_trial == TRUE), color = 'red')+
  scale_y_log10()+
  # scale_y_continuous(guide = 'axis_nested')
  theme_minimal()+
  facet_nested(~ model + phase + split , nest_line = element_line(linetype = 1))+
  theme(panel.background = element_rect(fill = "white", colour = NA), axis.ticks = element_line(colour = 'gray'))





plot_history <- function(
    metrics, 
    exp = 'data_dme',
    phn = 'ADHReplicates_hzg'
){
  mask <- (
    (metrics$exp == exp) &
      (metrics$phn == phn)
  )
  
  tmp <- metrics[mask, ] |>
    mutate(phase = case_when(
      phase == 'lightning' ~ 'Tuning', 
      phase == 'models' ~ 'Training'
    )) |>
    mutate(phase = factor(
      phase, 
      levels = c('Tuning', 'Training')
    )) |>
    group_by(exp, phn, model, phase, split, trial_index, epoch) |>
    mutate(loss = mean(loss)) |>
    select(-step) |>
    distinct()
  
  plt <- ggplot(
    filter(tmp, best_trial == FALSE #& model == 'VNN'
    ), 
    aes(x = epoch, y = loss, group = trial_index ))+
    geom_line(aes(color=best_trial), color = '#99999955')+
    geom_line(data = filter(tmp, best_trial == TRUE), color = 'red')+
    scale_y_log10()+
    # scale_y_continuous(guide = 'axis_nested')
    labs(x = 'Epoch', y = 'Loss (MSE)', title = paste0(exp, ': ', phn))+
    theme_minimal()+
    facet_nested(~ model + phase + split , nest_line = element_line(linetype = 1))+
    theme(panel.background = element_rect(fill = "white", colour = NA), axis.ticks = element_line(colour = 'gray'))
  
  return(plt)
}



plot_history(
    metrics, 
    exp = 'data_dme',
    phn = 'ADHReplicates_hzg'
)

# not expand grid but eg
eg <- metrics |> select(exp, phn) |> distinct()

plt_lst <- map(1:nrow(eg), function(i){
  plot_history(
    metrics, 
    exp = as.character(eg[i, 'exp']),
    phn = as.character(eg[i, 'phn'])
    )
})




p <- plt_lst
design <- "
ABCD
EFGH
"

p[[1]]+p[[2]]+p[[3]]+p[[4]]+p[[5]]+p[[6]]+p[[7]]+p[[8]]+plot_layout(design = design)


# overall  -- gmx looks really bad. The others have some that are okay 


```




```{r}
# there seem to be more than one record for some but not all taxa. 

vnn <- read_parquet('./yhat_vnn.parquet')
vnn |> 
  filter(
    version=='version_0',
    data_hash=='235ec0e852',
    split=='train',
    taxa=='LD00_3309'
  ) |> 
  select(yhat) |>
  summarise(yhat_sd = sd(yhat))

xx <- vnn |> 
  distinct() |>
  group_by(exp, phn, model, phase, version, data_hash, split, taxa) |>
  summarise(
    yhat = yhat,
    yhat_sd = sd(yhat)
    ) |>
  filter(!is.na(yhat_sd))

xx |> 
  mutate(frac = yhat_sd/yhat) |> 
  # select(-yhat) |> 
  arrange(desc(frac))
```






```{r}
# let's focus on a single experiment
# "premature optimization is the root of all evil"


# more flexible version
base_path <- '../data_zma/phno_all_Yield_Mg_ha__FTaxaREnvRGxE/vnn/models/vnn/version_0/'

base_path <- '../data_zma/phno_all_Yield_Mg_ha__FTaxaREnvRGxE/dnn/models/dnn/version_0/'



get_model_yhats <- function(base_path = '../data_zma/phno_all_Yield_Mg_ha__FTaxaREnvRGxE/dnn/models/dnn/version_0/'){
  tmp <- list.files(base_path)
  if(str_detect(base_path, '/lin/')){
    #TODO add functionality for linear model handeling here
    
  }else{
    yvar_cs_center <- read_parquet(paste0(base_path, tmp[str_detect(string = tmp, pattern = '.+yvar_cs_center.parquet$')] ))
    yvar_cs_scale  <- read_parquet(paste0(base_path, tmp[str_detect(string = tmp, pattern = '.+yvar_cs_scale.parquet$')] ))
    
    yvar_cs_trn    <- read_parquet(paste0(base_path, tmp[str_detect(string = tmp, pattern = '.+yvar_cs_trn.parquet$')] ))
    yvar_cs_val    <- read_parquet(paste0(base_path, tmp[str_detect(string = tmp, pattern = '.+yvar_cs_val.parquet$')] ))
    
    yhat_cs_trn    <- read_parquet(paste0(base_path, tmp[str_detect(string = tmp, pattern = '.+yhat_cs_trn.parquet$')] ))
    yhat_cs_val    <- read_parquet(paste0(base_path, tmp[str_detect(string = tmp, pattern = '.+yhat_cs_val.parquet$')] ))
    
    return(
      list(
        yvar_cs_center=yvar_cs_center,
        yvar_cs_scale=yvar_cs_scale,
        
        yvar_cs_trn=yvar_cs_trn,
        yvar_cs_val=yvar_cs_val,
        
        yhat_cs_trn=yhat_cs_trn,
        yhat_cs_val=yhat_cs_val
      ))
  }
}



res <- get_model_yhats(base_path = '../data_zma/phno_all_Yield_Mg_ha__FTaxaREnvRGxE/dnn/models/dnn/version_0/')
res <- get_model_yhats(base_path = '../data_zma/phno_all_Yield_Mg_ha__FTaxaREnvRGxE/vnn/models/vnn/version_0/')



yvar_cs_center <- res$yvar_cs_center
yvar_cs_scale  <- res$yvar_cs_scale
yvar_cs_trn    <- res$yvar_cs_trn
yvar_cs_val    <- res$yvar_cs_val
yhat_cs_trn    <- res$yhat_cs_trn
yhat_cs_val    <- res$yhat_cs_val


full_join(
  rename(yvar_cs_val, obsv = Yield_Mg_ha),
  rename(yhat_cs_val, yhat = Yield_Mg_ha)
)|> 
  ggplot(aes(obsv, yhat))+
  geom_point()+
  geom_smooth(method = 'lm')+
  geom_abline()


# do all vnns trained have this weird floor/ceil effect?


vnn_paths <- paste0(
  # '../data_zma/phno_all_Yield_Mg_ha__FTaxaREnvRGxE/vnn/models/vnn/version_', # yes
  # '../data_zma/phno_all_Yield_Mg_ha__IAH3_2021/vnn/models/vnn/version_', # can't say. Testing set is like 3 points. (should be more yes?)
  
  # '../data_zma/phno_all_Pollen_GDD__FTaxaREnvRGxE/vnn/models/vnn/version_', # two modes
  # '../data_zma/phno_all_Pollen_GDD__WIH2_2020/vnn/models/vnn/version_', # few to tell
  
  # '../data_gmx/phno_OilDry/vnn/models/vnn/version_', # spread but definite banding
  # '../data_gmx/phno_ProteinDry/vnn/models/vnn/version_', #
  # '../data_gmx/phno_StachyoseDry/vnn/models/vnn/version_', #
  
  
  
  
  # '../data_zma/phno_all_Yield_Mg_ha__FTaxaREnvRGxE/dnn/models/dnn/version_',
  # '../data_zma/phno_all_Yield_Mg_ha__IAH3_2021/dnn/models/dnn/version_',
  
  # '../data_zma/phno_all_Pollen_GDD__FTaxaREnvRGxE/dnn/models/dnn/version_',
  # '../data_zma/phno_all_Pollen_GDD__WIH2_2020/dnn/models/dnn/version_',
  
  # '../data_gmx/phno_OilDry/dnn/models/dnn/version_',
  # '../data_gmx/phno_ProteinDry/dnn/models/dnn/version_',
  '../data_gmx/phno_StachyoseDry/dnn/models/dnn/version_',
  
  c(0, 1, 2, 3, 4), '/')

plts <- list()
for(pth in vnn_paths){
  res <- get_model_yhats(base_path = pth)
  
  yvar_cs_val    <- res$yvar_cs_val
  yhat_cs_val    <- res$yhat_cs_val
  
  names(yvar_cs_val) <- c("obsv", "Split", "Phno_Idx", "Taxa")
  names(yhat_cs_val) <- c("yhat", "Split", "Phno_Idx", "Taxa")
  
  x <- full_join(
    yvar_cs_val,
    yhat_cs_val
    # rename(yvar_cs_val, obsv = Yield_Mg_ha),
    # rename(yhat_cs_val, yhat = Yield_Mg_ha)
  )
  plt <- ggplot(x, aes(obsv, yhat))+
    geom_point()+
    geom_smooth(method = 'lm')+
    geom_abline()  
  plts[[length(plts)+1]] <- plt
}

plts[[1]]+plts[[2]]+plts[[3]]+plts[[4]]+plts[[5]]+plot_layout(design = "ABCDE")
```








```{r}
# contrast performances

# Let's focus on a single one of these models: 
# exp == "data_dme" & phn == "ADHReplicates_hzg"


vnn <- read_parquet('./yhat_vnn.parquet')
dnn <- read_parquet('./yhat_dnn.parquet')
lin <- read_parquet('./yhat_lin.parquet')

vnn |> 
  distinct() |>
  group_by(exp, phn, model, phase, version, data_hash, split, taxa) |>
  tally() |>
  filter(n >1 )




lin |> filter(
  exp   == 'data_dme',
  phn   == 'ADHReplicates_hzg') |>
  select(data_hash) |> distinct()




  

f <- (function (x) x |> 
        filter(
          exp   == 'data_dme',
          phn   == 'ADHReplicates_hzg', 
          data_hash == '5540f41c30'
          )
      )

vnn <- vnn |> f()
dnn <- dnn |> f()
lin <- lin |> f()

vnn <- vnn |> select(exp, phn, phase, data_hash, split, taxa, yhat) |>      rename(vnn = yhat) |> distinct()
dnn <- dnn |> select(exp, phn, phase, data_hash, split, taxa, yhat) |>      rename(dnn = yhat) |> distinct()
lin <- lin |> select(exp, phn, phase, data_hash, split, taxa, obs, yhat) |> rename(lin = yhat) |> distinct()


# this is really curious. It seems like there are predictions that are offset by one between the taxa...
# > vnn |> arrange(split, taxa)
# # A tibble: 3,318 Ã— 7
#    exp      phn               phase  data_hash  split taxa         vnn
#    <chr>    <chr>             <chr>  <chr>      <chr> <chr>      <dbl>
#  1 data_dme ADHReplicates_hzg models 5540f41c30 test  11022 -0.0000463
#  2 data_dme ADHReplicates_hzg models 5540f41c30 test  11022 -0.0000548
#  3 data_dme ADHReplicates_hzg models 5540f41c30 test  11023 -0.0000548
#  4 data_dme ADHReplicates_hzg models 5540f41c30 test  11023 -0.0000491
#  5 data_dme ADHReplicates_hzg models 5540f41c30 test  11037 -0.0000491
#  6 data_dme ADHReplicates_hzg models 5540f41c30 test  11037 -0.0000462
#  7 data_dme ADHReplicates_hzg models 5540f41c30 test  11044 -0.0000462
#  8 data_dme ADHReplicates_hzg models 5540f41c30 test  11044 -0.0000443
#  9 data_dme ADHReplicates_hzg models 5540f41c30 test  11049 -0.000044


vnn |> group_by(exp, phn, phase, data_hash, split, taxa) |> tally()



full_join(lin, vnn)



full_join(
  (lin |> select(-obs) |> distinct()),
  vnn
)




```






```{r}

list.files('../data_gmx/phno_OilDry/vnn/models/vnn/version_0/')
list.files('../data_gmx/phno_OilDry/lin/models/blup/')





M <- read.csv('../data_gmx/phno_OilDry/vnn/models/vnn/version_0/metrics.csv')


ggplot()+
  geom_line(data = filter(select(M, step, train_loss), !is.na(train_loss)), 
            aes(x = step, y = train_loss))+
    geom_line(data = filter(select(M, step, val_loss), !is.na(val_loss)), 
            aes(x = step, y = val_loss), color = 'red')



read_parquet('../data_gmx/phno_OilDry/vnn/models/vnn/version_0/235ec0e852_yhat_trn.parquet')
read_parquet('../data_gmx/phno_OilDry/vnn/models/vnn/version_0/235ec0e852_yhat_val.parquet')


read_parquet('../data_gmx/phno_OilDry/lin/models/blup/15a0fac8d9_bWGR_b.parquet')
read_parquet('../data_gmx/phno_OilDry/lin/models/blup/15a0fac8d9_bWGR_mu.parquet')
read_parquet('../data_gmx/phno_OilDry/lin/models/blup/15a0fac8d9_bWGR_cxx.parquet')
read_parquet('../data_gmx/phno_OilDry/lin/models/blup/15a0fac8d9_bWGR_d.parquet')
read_parquet('../data_gmx/phno_OilDry/lin/models/blup/15a0fac8d9_bWGR_Vb.parquet')
read_parquet('../data_gmx/phno_OilDry/lin/models/blup/15a0fac8d9_bWGR_Ve.parquet')

```



```{r}
vnn <- read_parquet('./yhat_vnn.parquet')
dnn <- read_parquet('./yhat_dnn.parquet')
lin <- read_parquet('./yhat_lin.parquet')

# which have evidence of failed training? (sd == 0)

vnn |>
  group_by(exp, phn, model, phase, version, data_hash, split) |>
  summarise(sd = sd(yhat)) |>
  arrange(sd) |>
  # arrange(desc(sd)) |>
  print(n=40)

dnn |>
  group_by(exp, phn, model, phase, version, data_hash, split) |>
  summarise(sd = sd(yhat)) |>
  arrange(desc(sd))
  
  print(n=60)

lin |>
  group_by(exp, phn, model, phase, version, data_hash, split) |>
  summarise(sd = sd(yhat)) |>
  print(n=40)



f <- (function (x) x |> 
        filter(
          exp   == 'data_gmx',
          phn   == 'phno_OilDry', 
          data_hash == '1ebb200b12'
          )
      )

vnn <- vnn |> f()
dnn <- dnn |> f()
lin <- lin |> f()

vnn <- vnn |> select(exp, phn, phase, data_hash, split, taxa, yhat) |>      rename(vnn = yhat) |> distinct()
dnn <- dnn |> select(exp, phn, phase, data_hash, split, taxa, yhat) |>      rename(dnn = yhat) |> distinct()
lin <- lin |> select(exp, phn, phase, data_hash, split, taxa, obs, yhat) |> rename(lin = yhat) |> distinct()


# lin contains the observations so vnn and dnn are 1:1 and both are 1:many with lin
# dnn |> distinct() |> group_by(exp, phn, phase, data_hash, split, taxa) |> tally() |> filter(n != 1)

# TODO pseudoreplicates? 
# # A tibble: 30 Ã— 9
#    exp      phn             model phase  version   data_hash   yhat split taxa     
#    <chr>    <chr>           <chr> <chr>  <chr>     <chr>      <dbl> <chr> <chr>    
#  1 data_gmx phno_ProteinDry dnn   models version_4 361ee2ff57  45.0 train LD00_3309
#  2 data_gmx phno_ProteinDry dnn   models version_4 361ee2ff57  43.0 train LD00_3309
#  3 data_gmx phno_ProteinDry dnn   models version_3 7c2d03c704  44.6 train LD00_3309
#  4 data_gmx phno_ProteinDry dnn   models version_3 7c2d03c704  41.8 train LD00_3309
# dnn |> filter(taxa == 'LD00_3309')



M <- full_join(lin, full_join(vnn, dnn), relationship = 'many-to-many')


M |> 
  group_by(data_hash, split) |> 
  summarise(
    obs_vnn = cor(obs, vnn, use = 'pairwise.complete.obs'),
    obs_dnn = cor(obs, dnn, use = 'pairwise.complete.obs'),
    obs_lin = cor(obs, lin, use = 'pairwise.complete.obs')
    )




library(corrr)
M |> 
  group_by(data_hash) |>
  select(obs, lin, vnn, dnn) |>
  corrr::correlate()
  




vnn

dnn
 
lin



left_join(
  select(rename(vnn, vnn = yhat), -version),
  select(rename(dnn, dnn = yhat), -version)
) |> ggplot(
  aes(x = vnn, y = dnn)
)+geom_point()


rename(lin, lin = yhat)



vnn

f(vnn)
f(dnn)
f(lin)


vnn |>
  filter(exp   == 'data_zma',
         phn   == 'phno_all_Yield_Mg_ha__FTaxaREnvRGxE',
         model == 'vnn',
         phase == 'models'
         # version == 'version_3'
         ) |>
  ggplot(aes(x = interaction(split, data_hash), y = data_hash))+
  geom_point()
  


```


```{r}
vnn <- read_parquet('./yhat_vnn.parquet')
dnn <- read_parquet('./yhat_dnn.parquet')
lin <- read_parquet('./yhat_lin.parquet')


# this shows what we don't yet have.
do.call(
  rbind, 
  map(
    list(vnn, dnn, lin), 
    function(e){
      distinct(select(e, exp, phn, model, phase, data_hash))
      })
  ) |>
  mutate(exists = TRUE) |>
    ggplot(aes(
      x = model, 
      y = interaction(
        data_hash,
        # phase,
        phn,
        exp),
      fill = exists
      ))+
  geom_tile()+
  theme_bw()+
  scale_y_discrete(guide = "axis_nested")


xl <- lin |> 
  select(-model) |> 
  select(-version) |> 
  #   filter(
  #   exp == 'data_gmx',
  #   phn == 'phno_ProteinDry'
  #   # data_hash == '656a758935'
  # ) |>
  rename(lin = yhat)

xv <- vnn |> 
  select(-model) |> 
  select(-version) |> 
  # filter(
  #   exp == 'data_gmx',
  #   phn == 'phno_ProteinDry'
  #   # data_hash == '656a758935'
  # ) |>
  rename(vnn = yhat)

xd <- dnn |> 
  select(-model) |> 
  select(-version) |> 
  # filter(
  #   exp == 'data_gmx',
  #   phn == 'phno_ProteinDry'
  #   # data_hash == '656a758935'
  # ) |>
  rename(dnn = yhat)


xl$split |> unique()


xd





# TODO are testing values missing from the blups?
# xl |>
#   mutate(mse = (obs-lin)**2) |>
#   group_by(data_hash) |>
#   mutate(mse = mean(mse)) |>
#   ungroup() |>
#   ggplot(aes(x=data_hash, y = mse))+
#   geom_boxplot()





x <- full_join(full_join(xl, xv, relationship = "many-to-many"), xd, relationship = "many-to-many") 




x |>
  # filter(
    # phn == "phno_ProteinDry"
    # phn == "phno_StachyoseDry"
    # phn == "phno_OilDry"
    # phn == "phno_all_Pollen_GDD__FTaxaREnvRGxE"
    # phn == "phno_all_Pollen_GDD__WIH2_2020"
    # phn == "phno_all_Yield_Mg_ha__IAH3_2021"
    # phn == "ADHReplicates_hzg"
    # phn == "phno_all_Yield_Mg_ha__FTaxaREnvRGxE"
  # ) |>
  pivot_longer(cols = c('lin', 'vnn', 'dnn')) |>
  mutate(value = (obs-value)**2) |>
  # select(-obs) |>
  group_by(exp, phn, phase, data_hash, split, name) |>
  summarise(MSE = mean(value)) |>
  ungroup() |>
  ggplot(aes(x=interaction(split, name), y = MSE))+
  geom_boxplot(aes(fill = interaction(split, name)), width=0.1)+
  geom_point()+
  # scale_y_log10()+
  scale_x_discrete(guide = "axis_nested")+
  # facet_wrap(.~ )
  facet_nested(~ exp + phn , nest_line = element_line(linetype = 1), scales = 'free')+
  labs(x = '')+
  theme(
    panel.background = element_rect(fill = "white", colour = NA), 
    axis.ticks = element_line(colour = 'gray'),
    legend.position = 'none'
    )
  


x |>
  filter(
    # phn == "phno_ProteinDry"
    # phn == "phno_StachyoseDry"
    # phn == "phno_OilDry"
    # phn == "phno_all_Pollen_GDD__FTaxaREnvRGxE"
    # phn == "phno_all_Pollen_GDD__WIH2_2020"
    # phn == "phno_all_Yield_Mg_ha__IAH3_2021"
    # phn == "ADHReplicates_hzg"
    # phn == "phno_all_Yield_Mg_ha__FTaxaREnvRGxE"
  ) |>
  pivot_longer(cols = c('lin', 'vnn', 'dnn')) |>
  mutate(value = (obs-value)**2) |>
  # select(-obs) |>
  group_by(exp, phn, phase, data_hash, split, name) |>
  summarise(MSE = mean(value)) |>
  ungroup() |>
  ggplot(aes(x=interaction(split, name), y = MSE))+
  geom_boxplot(aes(fill = interaction(split, name)), width=0.1)+
  geom_point()+
  # scale_y_log10()+
  scale_x_discrete(guide = "axis_nested")+
  # facet_wrap(.~ )
  facet_nested(~ exp + phn , nest_line = element_line(linetype = 1), scales = 'free')+
  labs(x = '')+
  theme(
    panel.background = element_rect(fill = "white", colour = NA), 
    axis.ticks = element_line(colour = 'gray'),
    legend.position = 'none'
    )
  

```































































